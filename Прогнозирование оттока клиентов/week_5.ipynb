{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peer-graded Assignment: Эксперименты с моделью\n",
    "\n",
    "На прошлой неделе вы поучаствовали в соревновании на kaggle и, наверняка, большинство успешно справилось с прохождением baseline, а значит пора двигаться дальше - заняться оптимизацией модели, провести серию экспериментов и построить сильное финальное решения.\n",
    "\n",
    "В этом задании вам нужно провести ряд эскпериментов, оценить качество полученных в процессе экспериментирования моделей и выбрать лучшее решение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn import metrics\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import learning_curve\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import plotly.express as px"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "0. Подготовка датасета"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('orange_small_churn_train_data.csv', index_col=['ID'])\n",
    "df['labels'].fillna(0, inplace=True)\n",
    "labels, train = df['labels'], df.drop(columns=['labels'])\n",
    "labels.replace({-1: 0}, inplace=True)\n",
    "labels = labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "percent_missing = train.isnull().sum() * 100 / len(df)\n",
    "missing_value_df = pd.DataFrame({'percent_missing': percent_missing}).sort_values('percent_missing', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "    Var72     Var94  Var126  Var109    Var149  Var24  Var144      Var81  \\\nID                                                                        \n0     NaN       NaN     4.0   144.0  389396.0   20.0     9.0   14599.92   \n1     3.0   32289.0    40.0    80.0     735.0    2.0    18.0   67529.09   \n2     3.0   53388.0    36.0    40.0       0.0    0.0    27.0   85266.00   \n3     NaN       NaN     NaN    32.0       0.0    0.0     0.0   74107.20   \n4     3.0  106455.0   -28.0    32.0  554414.0    2.0     9.0  171072.90   \n\n   Var206    Var6  ...  Var73     Var113         Var212            Var193  \\\nID                 ...                                                      \n0    IYzP  3052.0  ...     34 -1209960.0     JBfYVit4g8           AERks4l   \n1    haYg  1813.0  ...    128   417932.0  XfqtO3UdzaXh_           2Knk1KF   \n2    hAFG  1953.0  ...    166  -124655.2  4kVnq_T26xq1p  LrdZy8QqgUfkVShG   \n3    IYzP  1533.0  ...     30   378473.6        NhsEn4L              RO12   \n4    zm5i   686.0  ...     32   142602.4        NhsEn4L              RO12   \n\n    Var210                  Var207  Var204  Var196 Var195   Var198  \nID                                                                  \n0     uKAI  GjJ35utlTa_GNSvxxpb9ju    k13i    1K8T   taul  UaKK0yW  \n1     uKAI              me75fM6ugJ    FbIm    1K8T   taul  Bnunsla  \n2     uKAI     7M47J5GA0pTYIFxg5uy    mTeA    1K8T   taul  fhk21Ss  \n3     uKAI              me75fM6ugJ    vzJD    1K8T   taul  uoZk2Zj  \n4     uKAI              me75fM6ugJ    m_h1    1K8T   taul  kugYdIL  \n\n[5 rows x 69 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Var72</th>\n      <th>Var94</th>\n      <th>Var126</th>\n      <th>Var109</th>\n      <th>Var149</th>\n      <th>Var24</th>\n      <th>Var144</th>\n      <th>Var81</th>\n      <th>Var206</th>\n      <th>Var6</th>\n      <th>...</th>\n      <th>Var73</th>\n      <th>Var113</th>\n      <th>Var212</th>\n      <th>Var193</th>\n      <th>Var210</th>\n      <th>Var207</th>\n      <th>Var204</th>\n      <th>Var196</th>\n      <th>Var195</th>\n      <th>Var198</th>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>144.0</td>\n      <td>389396.0</td>\n      <td>20.0</td>\n      <td>9.0</td>\n      <td>14599.92</td>\n      <td>IYzP</td>\n      <td>3052.0</td>\n      <td>...</td>\n      <td>34</td>\n      <td>-1209960.0</td>\n      <td>JBfYVit4g8</td>\n      <td>AERks4l</td>\n      <td>uKAI</td>\n      <td>GjJ35utlTa_GNSvxxpb9ju</td>\n      <td>k13i</td>\n      <td>1K8T</td>\n      <td>taul</td>\n      <td>UaKK0yW</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.0</td>\n      <td>32289.0</td>\n      <td>40.0</td>\n      <td>80.0</td>\n      <td>735.0</td>\n      <td>2.0</td>\n      <td>18.0</td>\n      <td>67529.09</td>\n      <td>haYg</td>\n      <td>1813.0</td>\n      <td>...</td>\n      <td>128</td>\n      <td>417932.0</td>\n      <td>XfqtO3UdzaXh_</td>\n      <td>2Knk1KF</td>\n      <td>uKAI</td>\n      <td>me75fM6ugJ</td>\n      <td>FbIm</td>\n      <td>1K8T</td>\n      <td>taul</td>\n      <td>Bnunsla</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>53388.0</td>\n      <td>36.0</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>27.0</td>\n      <td>85266.00</td>\n      <td>hAFG</td>\n      <td>1953.0</td>\n      <td>...</td>\n      <td>166</td>\n      <td>-124655.2</td>\n      <td>4kVnq_T26xq1p</td>\n      <td>LrdZy8QqgUfkVShG</td>\n      <td>uKAI</td>\n      <td>7M47J5GA0pTYIFxg5uy</td>\n      <td>mTeA</td>\n      <td>1K8T</td>\n      <td>taul</td>\n      <td>fhk21Ss</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>32.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>74107.20</td>\n      <td>IYzP</td>\n      <td>1533.0</td>\n      <td>...</td>\n      <td>30</td>\n      <td>378473.6</td>\n      <td>NhsEn4L</td>\n      <td>RO12</td>\n      <td>uKAI</td>\n      <td>me75fM6ugJ</td>\n      <td>vzJD</td>\n      <td>1K8T</td>\n      <td>taul</td>\n      <td>uoZk2Zj</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.0</td>\n      <td>106455.0</td>\n      <td>-28.0</td>\n      <td>32.0</td>\n      <td>554414.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>171072.90</td>\n      <td>zm5i</td>\n      <td>686.0</td>\n      <td>...</td>\n      <td>32</td>\n      <td>142602.4</td>\n      <td>NhsEn4L</td>\n      <td>RO12</td>\n      <td>uKAI</td>\n      <td>me75fM6ugJ</td>\n      <td>m_h1</td>\n      <td>1K8T</td>\n      <td>taul</td>\n      <td>kugYdIL</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 69 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[list(missing_value_df[missing_value_df.percent_missing < 50.].index)]\n",
    "train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def fillna_imputer(df):\n",
    "    '''\n",
    "    Заменяет Nan значения на строковый маркер 'Nan' и добавляет boolean столбец для каждого признака\n",
    "    '''\n",
    "    column_names = df.columns.to_list()\n",
    "    result = pd.DataFrame()\n",
    "    for name in column_names:\n",
    "        result[name] = df[name].fillna(value = 'missing')\n",
    "        result[name + '_bool'] = df[name].isna()\n",
    "    return result.reset_index(drop = True)\n",
    "\n",
    "bool_fillna_imputer = FunctionTransformer(fillna_imputer, validate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "numeric_features = list(set([f'Var{i}' for i in range(1, 191)]).intersection(set(train.columns)))\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "    ('variancethreshold', VarianceThreshold(0.1)),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = list(set([f'Var{i}' for i in range(191, 230)]).intersection(set(train.columns)))\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', bool_fillna_imputer),\n",
    "    ('onehot', ce.CatBoostEncoder(random_state=0)),\n",
    "    ('variancethreshold', VarianceThreshold(0.0))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RidgeClassifier(random_state=0, class_weight='balanced'))])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1\\. Начнем с простого. Давайте оценим как много объектов действительно нужно для построения качественной модели. Для обучения доступна достаточно большая выборка и может так оказаться, что начиная с некоторого момента рост размера обучающей выборки перестает влиять на качество модели. Постройте кривые обучения, обучая модель на выборках разного размера начиная с небольшого количество объектов в обучающей выборке и постепенно наращивая её размер с некоторым шагом. Обратите внимание на `sklearn.model_selection.learning_curve`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4391 samples were used to train the model\n",
      "The average train accuracy is 0.63\n",
      "The average test accuracy is 0.62\n",
      "8783 samples were used to train the model\n",
      "The average train accuracy is 0.63\n",
      "The average test accuracy is 0.61\n",
      "13175 samples were used to train the model\n",
      "The average train accuracy is 0.63\n",
      "The average test accuracy is 0.61\n"
     ]
    }
   ],
   "source": [
    "train_size_abs, train_scores, test_scores = learning_curve(\n",
    "    clf, train, labels, train_sizes=[0.3, 0.6, 0.9], shuffle=True, random_state=0\n",
    ")\n",
    "for train_size, cv_train_scores, cv_test_scores in zip(\n",
    "        train_size_abs, train_scores, test_scores\n",
    "):\n",
    "    print(f\"{train_size} samples were used to train the model\")\n",
    "    print(f\"The average train accuracy is {cv_train_scores.mean():.2f}\")\n",
    "    print(f\"The average test accuracy is {cv_test_scores.mean():.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.60832819, 0.62537129, 0.64572412, 0.64158058, 0.60779658])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, train, labels, scoring='balanced_accuracy', cv=5, n_jobs=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Примените к выборке технологию undersampling: для этого нужно убрать из обучения некоторое количество объектов большего класса таким образом, чтобы соотношение классов изменилось. Попробуйте не менее трёх различных вариантов undersampling (варианты могут отличаться как по количество отфильтрованных объектов, так и по принципу выборка объектов для отсеивания из выборки). Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "train_resampled, labels_resampled = rus.fit_resample(train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660 samples were used to train the model\n",
      "The average train accuracy is 0.67\n",
      "The average test accuracy is 0.59\n",
      "1321 samples were used to train the model\n",
      "The average train accuracy is 0.67\n",
      "The average test accuracy is 0.61\n",
      "1982 samples were used to train the model\n",
      "The average train accuracy is 0.68\n",
      "The average test accuracy is 0.62\n"
     ]
    }
   ],
   "source": [
    "train_size_abs, train_scores, test_scores = learning_curve(\n",
    "    clf, train_resampled, labels_resampled, train_sizes=[0.3, 0.6, 0.9], shuffle=True, random_state=0\n",
    ")\n",
    "for train_size, cv_train_scores, cv_test_scores in zip(\n",
    "        train_size_abs, train_scores, test_scores\n",
    "):\n",
    "    print(f\"{train_size} samples were used to train the model\")\n",
    "    print(f\"The average train accuracy is {cv_train_scores.mean():.2f}\")\n",
    "    print(f\"The average test accuracy is {cv_test_scores.mean():.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.5, 0.5, 0.5, 0.5, 0.5])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, train_resampled, labels_resampled, scoring='balanced_accuracy', cv=5, n_jobs=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Теперь перейдем к работе с признаками. Ранее вы реализовали несколько стратегий для обработки пропущенных значений. Сравните эти стратегии между собой с помощью оценки качества моделей кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка пропущенных значений сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Делал на прошлой неделе. Лучшая обработка в пайплайне"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Также вы уже реализовали несколько стратегий для обработки категориальных признаков. Сравните эти стратегии между собой с помощью оценки качества моделей по кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка категориальных признаков сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Делал на прошлой неделе. Лучшая обработка в пайплайне"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Все ли признаки оказались полезными для построения моделей? Проведите процедуру отбора признаков, попробуйте разные варианты отбора (обратите внимание на модуль `sklearn.feature_selection`). Например, можно выбрасывать случайные признаки или строить отбор на основе l1-регуляризации - отфильтровать из обучения признаки, которые получат нулевой вес при построении регрессии с l1-регуляризацией (`sklearn.linear_model.Lasso`). И всегда можно придумать что-то своё=) Попробуйте как минимум 2 различные стратегии, сравните результаты. Помог ли отбор признаков улучшить качество модели? Поясните свой ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.62287364, 0.62133745, 0.64720167, 0.63913943, 0.60642166])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('selector', SelectKBest(f_classif, k=70)),\n",
    "                      ('classifier', RidgeClassifier(random_state=0, class_weight='balanced'))])\n",
    "\n",
    "cross_val_score(clf, train, labels, scoring='balanced_accuracy', cv=5, n_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Подберите оптимальные параметры модели. Обратите внимание, что в зависимости от того, как вы обработали исходные данные, сделали ли балансировку классов, сколько объектов оставили в обучающей выборке и др. оптимальные значения параметров могут меняться. Возьмите наилучшее из ваших решений на текущий момент и проведите процедуру подбора параметров модели (обратите внимание на `sklearn.model_selection.GridSearchCV`) Как подбор параметров повлиял на качество модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(estimator=Pipeline(steps=[('preprocessor',\n                                        ColumnTransformer(transformers=[('num',\n                                                                         Pipeline(steps=[('imputer',\n                                                                                          SimpleImputer(strategy='median')),\n                                                                                         ('variancethreshold',\n                                                                                          VarianceThreshold(threshold=0.1)),\n                                                                                         ('scaler',\n                                                                                          StandardScaler())]),\n                                                                         ['Var44',\n                                                                          'Var13',\n                                                                          'Var153',\n                                                                          'Var112',\n                                                                          'Var73',\n                                                                          'Var173',\n                                                                          'Var113',\n                                                                          'Var7',\n                                                                          'Var21',\n                                                                          'Var6',\n                                                                          'Var163',\n                                                                          'Var74',\n                                                                          'Var76',\n                                                                          'V...\n                                                                          'Var223',\n                                                                          'Var226',\n                                                                          'Var227',\n                                                                          'Var204',\n                                                                          'Var195',\n                                                                          'Var203',\n                                                                          'Var216',\n                                                                          'Var192',\n                                                                          'Var205',\n                                                                          'Var211',\n                                                                          'Var221',\n                                                                          'Var197',\n                                                                          'Var206',\n                                                                          'Var210',\n                                                                          'Var196',\n                                                                          'Var220',\n                                                                          'Var199',\n                                                                          'Var217',\n                                                                          'Var207',\n                                                                          'Var219',\n                                                                          'Var218',\n                                                                          'Var228'])])),\n                                       ('selector', SelectKBest(k=70)),\n                                       ('classifier',\n                                        RidgeClassifier(class_weight='balanced',\n                                                        random_state=0))]),\n             param_grid={'classifier__alpha': [0.3, 0.5, 1.0]})"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'classifier__alpha':[0.3, 0.5, 1.]}\n",
    "grid = GridSearchCV(clf, parameters)\n",
    "grid.fit(train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "{'mean_fit_time': array([0.87957358, 0.78598628, 0.78994784]),\n 'std_fit_time': array([0.12553363, 0.08442278, 0.09005105]),\n 'mean_score_time': array([0.14152074, 0.12309847, 0.12329168]),\n 'std_score_time': array([0.03357628, 0.00636611, 0.00534279]),\n 'param_classifier__alpha': masked_array(data=[0.3, 0.5, 1.0],\n              mask=[False, False, False],\n        fill_value='?',\n             dtype=object),\n 'params': [{'classifier__alpha': 0.3},\n  {'classifier__alpha': 0.5},\n  {'classifier__alpha': 1.0}],\n 'split0_test_score': array([0.62595628, 0.62650273, 0.62377049]),\n 'split1_test_score': array([0.65409836, 0.65409836, 0.65491803]),\n 'split2_test_score': array([0.62595628, 0.62622951, 0.62759563]),\n 'split3_test_score': array([0.63224044, 0.63142077, 0.63114754]),\n 'split4_test_score': array([0.6373326 , 0.63569281, 0.63350642]),\n 'mean_test_score': array([0.63511679, 0.63478884, 0.63418762]),\n 'std_test_score': array([0.01040493, 0.01026587, 0.01087591]),\n 'rank_test_score': array([1, 2, 3])}"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Предложите методику оценки того, какие признаки внесли наибольший вклад в модель (например, это могут быть веса в случае регрессии, а также большое количество моделей реализуют метод `feature_importances_` - оценка важности признаков). На основе предложенной методики проанализируйте, какие признаки внесли больший вклад в модель, а какие меньший?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('variancethreshold',\n                                                                   VarianceThreshold(threshold=0.1)),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  ['Var44', 'Var13', 'Var153',\n                                                   'Var112', 'Var73', 'Var173',\n                                                   'Var113', 'Var7', 'Var21',\n                                                   'Var6', 'Var163', 'Var74',\n                                                   'Var76', 'Var94', 'Var57',\n                                                   'Var160',...\n                                                  ['Var202', 'Var212', 'Var222',\n                                                   'Var198', 'Var193', 'Var208',\n                                                   'Var223', 'Var226', 'Var227',\n                                                   'Var204', 'Var195', 'Var203',\n                                                   'Var216', 'Var192', 'Var205',\n                                                   'Var211', 'Var221', 'Var197',\n                                                   'Var206', 'Var210', 'Var196',\n                                                   'Var220', 'Var199', 'Var217',\n                                                   'Var207', 'Var219', 'Var218',\n                                                   'Var228'])])),\n                ('selector', SelectKBest(k=70)),\n                ('classifier',\n                 RidgeClassifier(class_weight='balanced', random_state=0))])"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.00873703, -0.06936441, -0.01672111, -0.20649621,  0.06872468,\n        -0.01982019,  0.06150716, -0.02960969,  0.01730626, -0.04536996,\n         0.01068546, -0.0143369 , -0.01289121, -0.09404157,  0.00826623,\n        -0.00463342, -0.02755816,  0.0288069 ,  0.01084958, -0.0096769 ,\n         0.02868448,  0.02723469,  0.03039234,  0.03875166, -0.0135567 ,\n         0.00783542,  0.02755343,  0.01398893,  0.13695176, -0.00810332,\n        -0.03249959,  0.01408752, -0.03398342,  0.02326126,  0.03361983,\n         0.0208979 ,  0.04927431,  0.01009069,  0.43307198, -0.09681323,\n        -0.07663755, -0.82860438, -0.89036375, -0.15872452, -0.03777044,\n         0.06679433, -1.21423399,  0.22223294, -0.15872452,  0.93785   ,\n         0.51889146,  0.36587896,  2.9733062 , -1.11172649, -0.3402967 ,\n         0.63123472, -0.15872452, -0.90870616, -0.22496969,  2.23703048,\n        -0.04369948, -0.09681323,  0.92323674,  0.30202941,  0.03612384,\n         1.14574887, -0.03777044,  2.45751935,  0.03612384, -0.47344445]])"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.named_steps['classifier'].coef_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}